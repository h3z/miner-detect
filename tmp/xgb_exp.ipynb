{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    " \n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from features.UserJoin import UserJoin\n",
    "from features.UserJoin import submit, diff, plt_month, plt_day, load_ids, info, infot\n",
    "import config as C\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import seaborn as sns\n",
    "from xgboost import plot_tree\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = UserJoin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具：打分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compare():\n",
    "    compare = pd.concat([pd.DataFrame({'id': list(C.true_ids), 'label': 1}),\n",
    "                         pd.DataFrame({'id': list(C.false_ids), 'label': 0}),\n",
    "                         # pd.DataFrame({'id': list(C.ids_4_2), 'label': .5}),\n",
    "                         # pd.DataFrame({'id': list(C.ids_4_2_V2), 'label': .5}),\n",
    "                        #  pd.DataFrame({'id': list(C.ids_13_4), 'label': .692})\n",
    "                         ])\n",
    "    compare = compare.set_index('id')\n",
    "    return compare\n",
    "\n",
    "def score(ids):\n",
    "    ids = list(ids)\n",
    "    compare = get_compare()\n",
    "    # print(f'共 {len(ids)} 忽略的 ', len(set(ids) - set(compare.index.values)))\n",
    "    compare = compare.join(pd.DataFrame({'id': ids, 'pred': 1}).set_index('id')).fillna(0)\n",
    "    compare = compare.reset_index()\n",
    "    # sns.jointplot(data=compare, x='label', y='pred')\n",
    "    # print(f'{np.mean((compare.pred - compare.label) ** 2):.3f}')\n",
    "    print(f'预测了 {len(ids)} 个, 未知/错了 {len(set(ids) - C.true_ids - C.false_ids)} / {(compare.pred != compare.label).sum()}')\n",
    "\n",
    "    return compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具：增加数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def aug1(df):\n",
    "#     df = df.copy()\n",
    "#     df.loc[df.index.isin(testids), 'IS_FLAG'] = 0\n",
    "#     return df\n",
    "\n",
    "# 把挖矿用户按比例变化，1个变成10个\n",
    "def aug2(df):\n",
    "    idmax = df.index.max()\n",
    "\n",
    "    d = df[df.IS_FLAG == 1]\n",
    "    p = d[['pq_f', 'pq_p', 'pq_g', 'pq_z']] * .002\n",
    "\n",
    "    newdfs = []\n",
    "    for i in range(-400, 500):\n",
    "        newd = d.copy()\n",
    "\n",
    "        newd[['pq_f', 'pq_p', 'pq_g', 'pq_z']] = newd[['pq_f', 'pq_p', 'pq_g', 'pq_z']] + p*i\n",
    "        newd = newd.reset_index()\n",
    "        newd.id = newd.id + idmax*(i+6)\n",
    "        newd = newd.set_index('id')\n",
    "\n",
    "        newdfs.append(newd)\n",
    "\n",
    "    return pd.concat(newdfs + [df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(features, df, params):\n",
    "    x, x_val = df.loc[df.label != 'test', features], df.loc[df.label == 'test', features]\n",
    "    y = df.loc[df.label != 'test', 'IS_FLAG']\n",
    "\n",
    "    model = xgb.XGBClassifier(**params)\n",
    "    model.fit(x, y)\n",
    "    pred_y = model.predict(x)\n",
    "    print((pred_y != y).sum())\n",
    "\n",
    "    y_val = model.predict(x_val)\n",
    "    pred_val = pd.DataFrame({'id': x_val.index.values, 'pred': y_val}).groupby('id').sum()\n",
    "    pred_y = pd.DataFrame({'id': x.index.values, 'ym': df.loc[df.label != 'test'].ym.values, 'pred': pred_y, 'label': y.values})\n",
    "    return pred_y, pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 之前 .88 的，不过 UserJoin 里做了一点小改动，所以结果不太一样了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:42] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0\n",
      "共预测了 39 个 1。 其中 8 未知\n",
      "0.190\n",
      "共预测了 34 个 1。 其中 3 未知\n",
      "0.238\n"
     ]
    }
   ],
   "source": [
    "_, pred = exp(C.month_features, ds.month, {})\n",
    "pred = pred[pred.pred > 7]\n",
    "\n",
    "score(pred.index.values)\n",
    "_ = score(load_ids('submit_3_7_1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 实验：复制了挖矿用户\n",
    "有那么一点点效果。 扩充测试集之后再看，好像效果也不好了。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "183\n"
     ]
    }
   ],
   "source": [
    "t = aug2(ds.month)\n",
    "y, pred = exp(C.month_features, t, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 35 忽略的  7\n",
      "0.310\n"
     ]
    }
   ],
   "source": [
    "tmp = pred[pred.pred > 13]\n",
    "_ = score(tmp.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 实验：组合月数据的全局统计\n",
    "这个尝试下来效果都不太好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ym', '   ', 'ELEC_TYPE_NAME', 'VOLT_NAME', 'PRC_NAME', 'CONTRACT_CAP', 'RUN_CAP', 'SHIFT_NO', 'BUILD_DATE', 'CANCEL_DATE', 'CHK_CYCLE', 'LAST_CHK_DATE', 'TMP_NAME', 'TMP_DATE', 'IS_FLAG', 'label', 'kwh_cal', 'kwh_pap_r2', 'kwh_pap_r3', 'kwh_pap_r4', 'pr2', 'pr3', 'pr4', '2_3', '2_4', '3_4', 'daycv']\n",
      "[15:33:01] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "user = ds.train[C.user_features]\n",
    "monthjoin = ds.month.join(user, rsuffix='_mean')\n",
    "\n",
    "mean_cols = []\n",
    "for i in monthjoin.columns:\n",
    "    if 'mean' in i:\n",
    "        monthjoin[i.replace('mean', 'sub_mean')] = monthjoin[i.replace('_mean', '')] - monthjoin[i]\n",
    "        mean_cols.append(i)\n",
    "\n",
    "monthjoin = monthjoin.drop(columns=mean_cols)\n",
    "\n",
    "monthjoin_features = [\n",
    "    'pq_f',\n",
    "    'pq_g',\n",
    "    'pq_p',\n",
    "    'pq_z',\n",
    "    'pf',\n",
    "    'pg',\n",
    "    'pp',\n",
    "    'p_f',\n",
    "    'p_g',\n",
    "    'f_g',\n",
    "    'monthcv',\n",
    "    # 'pq_f_mean',\n",
    "    # 'pq_g_mean',\n",
    "    # 'pq_p_mean',\n",
    "    # 'pq_z_mean',\n",
    "    # 'pp_mean',\n",
    "    # 'pf_mean',\n",
    "    # 'pg_mean',\n",
    "    # 'p_f_mean',\n",
    "    # 'p_g_mean',\n",
    "    # 'f_g_mean',\n",
    "    # 'monthcv_mean',\n",
    "\n",
    "    'pq_f_sub_mean',\n",
    "    'pq_g_sub_mean',\n",
    "    'pq_p_sub_mean',\n",
    "    'pq_z_sub_mean',\n",
    "    'pp_sub_mean',\n",
    "    'pf_sub_mean',\n",
    "    'pg_sub_mean',\n",
    "    'p_f_sub_mean',\n",
    "    'p_g_sub_mean',\n",
    "    'f_g_sub_mean',\n",
    "    'monthcv_sub_mean',\n",
    "]\n",
    "\n",
    "print([i for i in monthjoin.columns if i not in monthjoin_features])\n",
    "# monthjoin = aug2(monthjoin)\n",
    "y, pred = exp(monthjoin_features, monthjoin, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共 37 忽略的  7\n",
      "0.405\n"
     ]
    }
   ],
   "source": [
    "# pred[pred.pred > 0].hist()\n",
    "tmp = pred[pred.pred > 13]\n",
    "res = score(tmp.index.values)\n",
    "# res[res.label != res.pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 实验：尝试一些调参相关的。然后用 gridsearch 试试看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fjoin(df):\n",
    "    user = ds.train[C.user_features]\n",
    "    monthjoin = df.join(user, rsuffix='_mean')\n",
    "\n",
    "    mean_cols = []\n",
    "    for i in monthjoin.columns:\n",
    "        if 'mean' in i:\n",
    "            monthjoin[i.replace('mean', 'sub_mean')] = monthjoin[i.replace('_mean', '')] - monthjoin[i]\n",
    "            mean_cols.append(i)\n",
    "\n",
    "    monthjoin = monthjoin.drop(columns=mean_cols)\n",
    "\n",
    "    monthjoin_features = [\n",
    "        'pq_f',\n",
    "        'pq_g',\n",
    "        'pq_p',\n",
    "        'pq_z',\n",
    "        'pf',\n",
    "        'pg',\n",
    "        'pp',\n",
    "        'p_f',\n",
    "        'p_g',\n",
    "        'f_g',\n",
    "        'monthcv',\n",
    "        # 'pq_f_mean',\n",
    "        # 'pq_g_mean',\n",
    "        # 'pq_p_mean',\n",
    "        # 'pq_z_mean',\n",
    "        # 'pp_mean',\n",
    "        # 'pf_mean',\n",
    "        # 'pg_mean',\n",
    "        # 'p_f_mean',\n",
    "        # 'p_g_mean',\n",
    "        # 'f_g_mean',\n",
    "        # 'monthcv_mean',\n",
    "\n",
    "        'pq_f_sub_mean',\n",
    "        'pq_g_sub_mean',\n",
    "        'pq_p_sub_mean',\n",
    "        'pq_z_sub_mean',\n",
    "        'pp_sub_mean',\n",
    "        'pf_sub_mean',\n",
    "        'pg_sub_mean',\n",
    "        'p_f_sub_mean',\n",
    "        'p_g_sub_mean',\n",
    "        'f_g_sub_mean',\n",
    "        'monthcv_sub_mean',\n",
    "    ]\n",
    "\n",
    "    return monthjoin, monthjoin_features\n",
    "\n",
    "\n",
    "def today_exp(params, aug=False, join=False):\n",
    "    params['use_label_encoder'] = False\n",
    "\n",
    "    t = ds.month\n",
    "    # t = ds.month[ds.month.index.isin(ds.train1.index)]\n",
    "    cols = C.month_features\n",
    "    if aug:\n",
    "        t = aug2(t)\n",
    "    elif join:\n",
    "        t, cols = fjoin(t)\n",
    "    pred_y, pred_val = exp(cols, t, params)\n",
    "\n",
    "    for i in range(10):\n",
    "        t = pred_y[pred_y.pred == 1]\n",
    "        t = t.groupby('id').count()\n",
    "        ids = set(t[t.ym > i].index.values)\n",
    "        # print(f' > {i}, {len(ids & set(C.minerids))} / {len(ids)}')\n",
    "\n",
    "        if len(ids) < 10:\n",
    "            break\n",
    "\n",
    "    for i in range(22):\n",
    "        ids = pred_val[pred_val.pred > i].index.values\n",
    "        if len(ids) > 40:\n",
    "            continue\n",
    "        if len(ids) == 0:\n",
    "            break\n",
    "        print(f'val: > {i}', end=', ')\n",
    "        score(ids)\n",
    "\n",
    "    # return pred_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:38:26] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "126\n",
      "val: > 6, 预测了 40 个 1, 未知/错了 6 / 9\n",
      "val: > 7, 预测了 36 个 1, 未知/错了 4 / 9\n",
      "val: > 8, 预测了 31 个 1, 未知/错了 3 / 11\n",
      "val: > 9, 预测了 25 个 1, 未知/错了 2 / 12\n"
     ]
    }
   ],
   "source": [
    "today_exp({\n",
    "    'max_depth': 3,  # 3–10\n",
    "    'n_estimators': 100,  # 100(lots of observations) to 1000 (few observations)\n",
    "    'learning_rate': 0.01,  # 0.01~0.3\n",
    "    'colsample_bytree': 0.5,  # 0.5–1\n",
    "    'subsample': 0.6  # 0.6–1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:15:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0\n",
      "val: > 7, 预测了 39 个, 未知/错了 8 / 8\n",
      "val: > 8, 预测了 34 个, 未知/错了 5 / 8\n",
      "val: > 9, 预测了 29 个, 未知/错了 3 / 11\n",
      "val: > 10, 预测了 24 个, 未知/错了 2 / 13\n",
      "val: > 11, 预测了 23 个, 未知/错了 1 / 13\n",
      "val: > 12, 预测了 22 个, 未知/错了 1 / 12\n",
      "val: > 13, 预测了 20 个, 未知/错了 1 / 14\n",
      "val: > 14, 预测了 17 个, 未知/错了 1 / 13\n",
      "val: > 15, 预测了 15 个, 未知/错了 1 / 15\n",
      "val: > 16, 预测了 12 个, 未知/错了 0 / 17\n",
      "val: > 17, 预测了 11 个, 未知/错了 0 / 18\n",
      "val: > 18, 预测了 10 个, 未知/错了 0 / 19\n",
      "val: > 19, 预测了 7 个, 未知/错了 0 / 22\n",
      "val: > 20, 预测了 5 个, 未知/错了 0 / 24\n"
     ]
    }
   ],
   "source": [
    "pred_val = today_exp({\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.3,\n",
    "    'colsample_bytree': 1,\n",
    "    'subsample': 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:41:09] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "45\n",
      "val: > 7, 预测了 40 个, 未知/错了 7 / 10\n",
      "val: > 8, 预测了 34 个, 未知/错了 4 / 9\n",
      "val: > 9, 预测了 29 个, 未知/错了 3 / 11\n"
     ]
    }
   ],
   "source": [
    "today_exp({\n",
    "    'max_depth': 5,  # 3–10\n",
    "    'n_estimators': 200,  # 100(lots of observations) to 1000 (few observations)\n",
    "    'learning_rate': 0.05,  # 0.01~0.3\n",
    "    'colsample_bytree': .8,  # 0.5–1\n",
    "    'subsample': .8  # 0.6–1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:35] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1\n",
      "val: > 7, 预测了 39 个, 未知/错了 8 / 10\n",
      "val: > 8, 预测了 35 个, 未知/错了 6 / 8\n",
      "val: > 9, 预测了 33 个, 未知/错了 4 / 8\n",
      "val: > 10, 预测了 30 个, 未知/错了 4 / 11\n",
      "val: > 11, 预测了 28 个, 未知/错了 3 / 10\n",
      "val: > 12, 预测了 25 个, 未知/错了 2 / 10\n",
      "val: > 13, 预测了 23 个, 未知/错了 1 / 11\n",
      "val: > 14, 预测了 21 个, 未知/错了 0 / 12\n",
      "val: > 15, 预测了 19 个, 未知/错了 0 / 14\n",
      "val: > 16, 预测了 18 个, 未知/错了 0 / 15\n",
      "val: > 17, 预测了 14 个, 未知/错了 0 / 17\n",
      "val: > 18, 预测了 12 个, 未知/错了 0 / 19\n",
      "val: > 19, 预测了 8 个, 未知/错了 0 / 21\n",
      "val: > 20, 预测了 6 个, 未知/错了 0 / 23\n"
     ]
    }
   ],
   "source": [
    "today_exp({\n",
    "    'max_depth': 5,  # 3–10\n",
    "    'n_estimators': 500,  # 100(lots of observations) to 1000 (few observations)\n",
    "    'learning_rate': 0.05,  # 0.01~0.3\n",
    "    'colsample_bytree': .8,\n",
    "    'subsample': .8,\n",
    "    # 'lambda': 10\n",
    "}, False, False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ecdeaf2ac59fb4ad11976aef5258ba241a9bb1bfad09d91039c8d9c71c1b3462"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('miner')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
